import os
import tensorflow as tf
import datetime

from preproc.preproc import get_list_of_paths, preprocess
from model.model import Generator, Discriminator, mae, fit, save_model


tf.config.set_visible_devices([], 'GPU')
print("Devices visibles :", tf.config.list_physical_devices())

# -----------------------------
# Param√®tres
# -----------------------------
DATA_DIR = "./raw_data/catsdata"
BATCH_SIZE = 32
IMAGE_SIZE = 256
EPOCHS = 20  # augmenter √† 10, 20‚Ä¶ si besoins

# -----------------------------
# Dataset
# -----------------------------
jpg_paths, _ = get_list_of_paths(DATA_DIR)
print(f"üñºÔ∏è  {len(jpg_paths)} images trouv√©es dans {DATA_DIR}")

ds = tf.data.Dataset.from_tensor_slices(jpg_paths)
ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
print("‚úÖ Dataset pr√™t (LAB normalis√© 256√ó256)")

split_ratio = 0.2
test_len = int(len(ds) * split_ratio)
test_ds = ds.take(test_len)
train_ds = ds.skip(test_len)
print(f"‚úÖ Split train/test fait (‚âà {int((1-split_ratio)*100)}% / {int(split_ratio*100)}%)")

# -----------------------------
# Mod√®les + optimizers
# -----------------------------
generator = Generator(IMAGE_SIZE)
generator.compile(loss=mae, optimizer="adam")
print("‚úÖ Generator cr√©√©")

generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

discriminator = Discriminator(image_size=IMAGE_SIZE)
print("‚úÖ Discriminator cr√©√©")

checkpoint_dir = "./training_checkpoints"
os.makedirs(checkpoint_dir, exist_ok=True)
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")

checkpoint = tf.train.Checkpoint(
    generator_optimizer=generator_optimizer,
    discriminator_optimizer=discriminator_optimizer,
    generator=generator,
    discriminator=discriminator,
)

# -----------------------------
# TensorBoard log dir + batch de samples
# -----------------------------
log_dir = f"logs/gan_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}"
sample_batch = next(iter(test_ds))  # (L_batch, AB_batch)

# -----------------------------
# Entra√Ænement GAN
# -----------------------------

fit(
    train_ds,
    EPOCHS,
    generator,
    discriminator,
    generator_optimizer,
    discriminator_optimizer,
    checkpoint,
    checkpoint_prefix,
    log_dir=log_dir,
    sample_batch=sample_batch,
)

# -----------------------------
# Sauvegarde du mod√®le pour l'API FastAPI
# -----------------------------
MODEL_PATH = "model_trained.keras"
save_model(generator, MODEL_PATH, bucket_name=None)  # local uniquement
